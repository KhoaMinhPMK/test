import pandas as pd
import numpy as np

print("ğŸ” PHÃ‚N TÃCH Káº¾T QUáº¢ FEATURE EXTRACTION")
print("=" * 50)

# 1. PhÃ¢n tÃ­ch dataset chÃ­nh
print("\nğŸ“Š 1. PHÃ‚N TÃCH DATASET CHÃNH:")
df = pd.read_csv('data/extracted_features.csv')
print(f"   Dataset shape: {df.shape}")
print(f"   Tá»•ng sá»‘ samples: {len(df):,}")

# Label distribution
label_counts = df['label'].value_counts()
print(f"\n   ğŸ“‹ PhÃ¢n bá»‘ labels:")
for label, count in label_counts.items():
    percentage = count / len(df) * 100
    label_name = "Normal" if label == 0 else "Falling"
    print(f"      {label_name} (label={label}): {count:,} samples ({percentage:.1f}%)")

# Imbalance ratio
imbalance_ratio = label_counts[0] / label_counts[1] if 1 in label_counts else float('inf')
print(f"   ğŸ“Š Tá»· lá»‡ máº¥t cÃ¢n báº±ng (Normal:Falling): {imbalance_ratio:.1f}:1")

# Features
feature_columns = [col for col in df.columns if col not in ['file_name', 'window_start', 'window_end', 'label', 'fall_ratio']]
print(f"   ğŸ¯ Sá»‘ Ä‘áº·c trÆ°ng: {len(feature_columns)}")

# Feature types
feature_types = {}
for col in feature_columns:
    prefix = col.split('_')[0]
    if prefix not in feature_types:
        feature_types[prefix] = 0
    feature_types[prefix] += 1

print(f"\n   ğŸ“‹ Loáº¡i Ä‘áº·c trÆ°ng:")
for feat_type, count in feature_types.items():
    print(f"      {feat_type}: {count} features")

# 2. PhÃ¢n tÃ­ch Feature Importance
print(f"\nğŸ“Š 2. PHÃ‚N TÃCH FEATURE IMPORTANCE:")
importance_df = pd.read_csv('data/feature_importance.csv')

print(f"\n   ğŸ† TOP 10 Äáº¶C TRÆ¯NG QUAN TRá»ŒNG NHáº¤T:")
top_10 = importance_df.head(10)
for i, row in top_10.iterrows():
    print(f"      {i+1:2d}. {row['feature']:<25} | Score: {row['combined_score']:.4f}")

print(f"\n   ğŸ“‹ PhÃ¢n loáº¡i top 10 theo nhÃ³m:")
top_10_types = {}
for _, row in top_10.iterrows():
    prefix = row['feature'].split('_')[0]
    if prefix not in top_10_types:
        top_10_types[prefix] = 0
    top_10_types[prefix] += 1

for feat_type, count in top_10_types.items():
    print(f"      {feat_type}: {count} features")

# 3. Insights vá» Ä‘áº·c trÆ°ng
print(f"\nğŸ§  3. INSIGHTS Vá»€ Äáº¶C TRÆ¯NG:")

print(f"\n   âœ… Äáº·c trÆ°ng thá»‘ng kÃª (stat_) chiáº¿m Æ°u tháº¿:")
stat_features = importance_df[importance_df['feature'].str.startswith('stat_')].head(5)
print(f"      - stat_skewness vÃ  stat_kurtosis lÃ  2 Ä‘áº·c trÆ°ng quan trá»ng nháº¥t")
print(f"      - Cho tháº¥y phÃ¢n bá»‘ dá»¯ liá»‡u cÃ³ vai trÃ² quan trá»ng trong phÃ¢n loáº¡i")

print(f"\n   âœ… Äáº·c trÆ°ng chuyá»ƒn Ä‘á»™ng (motion_) quan trá»ng:")
motion_features = importance_df[importance_df['feature'].str.startswith('motion_')].head(3)
print(f"      - motion_displacement: Ä‘á»™ dá»‹ch chuyá»ƒn tá»•ng thá»ƒ")
print(f"      - Pháº£n Ã¡nh sá»± thay Ä‘á»•i vá»‹ trÃ­ khi ngÃ£")

print(f"\n   âœ… Äáº·c trÆ°ng hÃ¬nh há»c (geo_) cÆ¡ báº£n:")
geo_features = importance_df[importance_df['feature'].str.startswith('geo_')].head(3)
print(f"      - geo_aspect_ratio: tá»· lá»‡ khung hÃ¬nh")
print(f"      - geo_width, geo_height: kÃ­ch thÆ°á»›c bbox")

print(f"\n   âœ… Äáº·c trÆ°ng tÆ° tháº¿ (pose_) chi tiáº¿t:")
pose_features = importance_df[importance_df['feature'].str.startswith('pose_')].head(3)
print(f"      - pose_orientation: hÆ°á»›ng cÆ¡ thá»ƒ")
print(f"      - Quan trá»ng Ä‘á»ƒ phÃ¢n biá»‡t Ä‘á»©ng/náº±m")

# 4. ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng
print(f"\nğŸ“ˆ 4. ÄÃNH GIÃ CHáº¤T LÆ¯á»¢NG:")

print(f"\n   âœ… Æ¯u Ä‘iá»ƒm:")
print(f"      - Dataset Ä‘á»§ lá»›n: {len(df):,} samples")
print(f"      - Äa dáº¡ng Ä‘áº·c trÆ°ng: {len(feature_columns)} features tá»« 6 nhÃ³m")
print(f"      - Sliding window táº¡o nhiá»u samples tá»« Ã­t video")
print(f"      - Feature importance rÃµ rÃ ng, cÃ³ Ã½ nghÄ©a")

print(f"\n   âš ï¸ ThÃ¡ch thá»©c:")
print(f"      - Máº¥t cÃ¢n báº±ng dá»¯ liá»‡u nghiÃªm trá»ng: {imbalance_ratio:.1f}:1")
print(f"      - Cáº§n cÃ¢n báº±ng dá»¯ liá»‡u trÆ°á»›c khi training")
print(f"      - Má»™t sá»‘ Ä‘áº·c trÆ°ng cÃ³ thá»ƒ redundant")

# 5. Khuyáº¿n nghá»‹
print(f"\nğŸ’¡ 5. KHUYáº¾N NGHá»Š:")
print(f"\n   ğŸ¯ Cho bÆ°á»›c tiáº¿p theo:")
print(f"      1. Sá»­ dá»¥ng top 20-30 features quan trá»ng nháº¥t")
print(f"      2. Ãp dá»¥ng data balancing (SMOTE, oversampling)")
print(f"      3. Thá»­ cÃ¡c model: Random Forest, SVM, Neural Network")
print(f"      4. Cross-validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ robust")
print(f"      5. Feature engineering thÃªm náº¿u cáº§n")

print(f"\n   ğŸ“Š Balanced datasets Ä‘Ã£ táº¡o:")
try:
    import os
    balanced_files = [f for f in os.listdir('data') if f.startswith('balanced_data_')]
    for file in balanced_files:
        print(f"      - {file}")
except:
    print(f"      - ChÆ°a cÃ³ balanced datasets")

print(f"\nğŸ‰ Káº¾T LUáº¬N:")
print(f"   Thuáº­t toÃ¡n feature extraction Ä‘Ã£ thÃ nh cÃ´ng!")
print(f"   Dataset cÃ³ cháº¥t lÆ°á»£ng tá»‘t vá»›i {len(feature_columns)} Ä‘áº·c trÆ°ng Ä‘a dáº¡ng.")
print(f"   Sáºµn sÃ ng cho bÆ°á»›c training model machine learning.") 